{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d12c481-09bc-4bfd-80bf-1421162d3ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:60000,columns:784\n",
      "Rows: 10000, columns: 784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mnist 手写数字图形识别\n",
    "from __future__ import print_function\n",
    "import os \n",
    "import struct \n",
    "import numpy as np \n",
    "import cv2\n",
    "# 加载mnist\n",
    "def load_mnist(path,kind='train'):\n",
    "    labels_path = os.path.join(path,'%s-labels.idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path,'%s-images.idx3-ubyte' % kind)\n",
    "    with open(labels_path,'rb') as lbpath:\n",
    "        magic,n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels= np.fromfile(lbpath,dtype=np.uint8)\n",
    "    with open(images_path,'rb') as imgpath:\n",
    "        magic,num,rows,cols= struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels),rows*cols)\n",
    "    return images,labels\n",
    "\n",
    "x_train, y_train = load_mnist('./data', kind='train')\n",
    "print('Rows:%d,columns:%d' % (x_train.shape[0],x_train.shape[1]))\n",
    "x_test, y_test = load_mnist('./data', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "image1 = x_train[1].astype('float32').reshape(28,28,1)\n",
    "cv2.imwrite('./data/1.jpg',image1)\n",
    "\n",
    "img = cv2.imread('./data/1.jpg')\n",
    "cv2.imshow(\"0\",img)\n",
    "cv2.waitKey(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73eeccd2-a8aa-4552-9cfe-d8284fe7ac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Normalize(mean=(0.1307,), std=0.3081)\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Normalize(mean=(0.1307,), std=0.3081)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "img should be Tensor Image. Got <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 123\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\u001b[38;5;66;03m# 训练和测试进行五轮\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m         test()\n",
      "Cell \u001b[1;32mIn[16], line 79\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m():\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28minput\u001b[39m,target \u001b[38;5;241m=\u001b[39m data \u001b[38;5;66;03m# input 作为输入数据，target 作为标签\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()   \u001b[38;5;66;03m# 梯度清零\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:361\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    359\u001b[0m     _log_api_usage_once(normalize)\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mnormalize(tensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, inplace\u001b[38;5;241m=\u001b[39minplace)\n",
      "\u001b[1;31mTypeError\u001b[0m: img should be Tensor Image. Got <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision.datasets import MNIST \n",
    "from torchvision import transforms\n",
    "from torch import nn \n",
    "import os \n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "# 初始化数据内容和标签\n",
    "def __init__(self,Data,Label):\n",
    "    self.Data = Data\n",
    "    self.Label = Label\n",
    "    \n",
    "# 获取数据内容和标签\n",
    "def __getItem__(self,idx):\n",
    "    data = torch.Tensor(self.Data[idx])\n",
    "    label = torch.Tensor(self.Label[idx])\n",
    "\n",
    "# 获取数据集大小\n",
    "def __len__(self):\n",
    "    return len(self.Data)\n",
    "\n",
    "# 数据加载类 DataLoader\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose({\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.1307,),(0.3081))\n",
    "})\n",
    "\n",
    "# 加载数据集\n",
    "train_data = MNIST(root='./data',train=True,download=False,transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_data,shuffle=True,batch_size=64)\n",
    "\n",
    "# 测试数据集\n",
    "test_data = MNIST(root='./data',train=False,download=False,transform=transform.toTensor())\n",
    "test_loader = DataLoader(test_data,shuffle=False,batch_size=64)\n",
    "print(train_data)\n",
    "print(test_data)\n",
    "\n",
    "\n",
    "class Model(nn.Module): # 模型构建\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.linear1 = nn.Linear(784,256)\n",
    "        self.linear2 = nn.Linear(256,64)\n",
    "        # 10 个手写数字对应的10个输出\n",
    "        self.linear3 = nn.Linear(64,10) \n",
    "    def forward(self,x):\n",
    "        # 变形\n",
    "        x = x.view(-1,784)\n",
    "        # relu(Rectified Linear Unit) 修正线性单元  \n",
    "        # 当X <=0 时，relu = 0 , 当x >0 时，relu = x ;\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = torch.relu(self.linear3(x))\n",
    "        return x\n",
    "\n",
    "# 损失函数 交叉熵损失函数 CrossEntropyLoss\n",
    "# 分为三步  1. Softmax  2. Log  3.NllLoss \n",
    "\n",
    "# Softmax回归是一个线性多分类模型，softmax 最终会给出预测值对于10个类别（0-9）出现的概率\n",
    "# 最终模型的预测结果就是概率最大的类别，Softmax 计算公式如下\n",
    "model = Model()\n",
    "# 计算交叉熵损失，相当于 softmax+log+nllloss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器 SGD \n",
    "# 第一个参数是初始化参数值，第二个参数是学习率\n",
    "optimizer = torch.optim.SGD(model.parameters(),0.8)\n",
    "\n",
    "# 模型训练\n",
    "def train():\n",
    "    for index,data in enumerate(train_loader):\n",
    "        input,target = data # input 作为输入数据，target 作为标签\n",
    "        optimizer.zero_grad()   # 梯度清零\n",
    "        y_predict = model(input)    # 模型预测\n",
    "        loss = criterion(y_predict,target)    # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        if index % 100 ==0:  # 每训练100次，保存模型\n",
    "            torch.save(model.state_dict(),\"./model/model.pkl\") # 保存模型\n",
    "            torch.save(optimizer.state_dict(),\"./model/optimizer.pkl\")  # 保存优化器\n",
    "            print(\"损失值：%.2f\" % loss.item())\n",
    "\n",
    "# 加载模型 \n",
    "if os.path.exists('./model/model.pkl'):\n",
    "    model.load_state_dict(torch.load(\"./model/model.pkl\"))\n",
    "# 模型测试\n",
    "def test():\n",
    "    correct = 0  # 定义正确模型个数\n",
    "    total = 0 # 总数\n",
    "    with torch.no_grad(): # 测试不进行梯度计算\n",
    "        for data in test_loader:\n",
    "            input,target = data\n",
    "            output = model(input) # output输出10个预测取值，其中最大的即为预测的数\n",
    "            probability,predict = torch.max(output.data,dim=1) # 返回一个元组，第一个为最大概率值，第二个为最大概率值的下标\n",
    "            total +=target.size(0) # target是形状为(batch_size,1)的矩阵，使用size(0)取出该批的大小 \n",
    "            correct += (predict == target).sum().item() # predict和target均为(batch_size,1)的矩阵，sum()求出相等的个数\n",
    "        print(\"准确率为：%.2f\" % (correct / total))\n",
    "\n",
    "def test_mydata():\n",
    "    image = Image.open('./data/1.png') # 读取自定义的手写图片\n",
    "    image = image.resize(28,28) # 裁剪尺寸为 28*28 \n",
    "    image = image.convert('L') # 转换为灰度图像 \n",
    "    transform = transforms.toTensor() \n",
    "    image = transform(image)\n",
    "    image = image.resize(1,1,28,28)\n",
    "    output = model(image)\n",
    "    probability,predict = torch.max(output.data,dim=1)\n",
    "    print('此手写图片值为%d,其最大的概率为：%.2f' % (predict[0],probability))\n",
    "    plt.title('此手写图片值为：{}'.format((int(predict))),fontname='SimHei')\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.show()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    for i in range(5):# 训练和测试进行五轮\n",
    "        train()\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e4b65-087f-4c6a-b84e-686172f92974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
