{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d12c481-09bc-4bfd-80bf-1421162d3ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:60000,columns:784\n",
      "Rows: 10000, columns: 784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mnist 手写数字图形识别\n",
    "from __future__ import print_function\n",
    "import os \n",
    "import struct \n",
    "import numpy as np \n",
    "import cv2\n",
    "# 加载mnist\n",
    "def load_mnist(path,kind='train'):\n",
    "    labels_path = os.path.join(path,'%s-labels.idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path,'%s-images.idx3-ubyte' % kind)\n",
    "    with open(labels_path,'rb') as lbpath:\n",
    "        magic,n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels= np.fromfile(lbpath,dtype=np.uint8)\n",
    "    with open(images_path,'rb') as imgpath:\n",
    "        magic,num,rows,cols= struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels),rows*cols)\n",
    "    return images,labels\n",
    "\n",
    "x_train, y_train = load_mnist('./data', kind='train')\n",
    "print('Rows:%d,columns:%d' % (x_train.shape[0],x_train.shape[1]))\n",
    "x_test, y_test = load_mnist('./data', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "image1 = x_train[1].astype('float32').reshape(28,28,1)\n",
    "cv2.imwrite('./data/1.jpg',image1)\n",
    "\n",
    "img = cv2.imread('./data/1.jpg')\n",
    "cv2.imshow(\"0\",img)\n",
    "cv2.waitKey(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73eeccd2-a8aa-4552-9cfe-d8284fe7ac35",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 37\u001b[0m\n\u001b[0;32m     31\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose({\n\u001b[0;32m     32\u001b[0m   transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     33\u001b[0m   transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.1307\u001b[39m,),(\u001b[38;5;241m0.03081\u001b[39m))\n\u001b[0;32m     34\u001b[0m })\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 加载数据集\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_data,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 测试数据集\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Users\\GaryDeng\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:102\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_data()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision.datasets import MNIST \n",
    "from torchvision import transforms\n",
    "from torch import nn \n",
    "import os \n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "# 初始化数据内容和标签\n",
    "def __init__(self,Data,Label):\n",
    "    self.Data = Data\n",
    "    self.Label = Label\n",
    "    \n",
    "# 获取数据内容和标签\n",
    "def __getItem__(self,idx):\n",
    "    data = torch.Tensor(self.Data[idx])\n",
    "    label = torch.Tensor(self.Label[idx])\n",
    "\n",
    "# 获取数据集大小\n",
    "def __len__(self):\n",
    "    return len(self.Data)\n",
    "\n",
    "# 数据加载类 DataLoader\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose({\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.1307,),(0.03081))\n",
    "})\n",
    "\n",
    "# 加载数据集\n",
    "train_data = MNIST(root='./data',train=True,download=False,transform=transform)\n",
    "train_loader = DataLoader(train_data,shuffle=True,batch_size=64)\n",
    "\n",
    "# 测试数据集\n",
    "test_data = MNIST(root='./data',train=False,download=False,transform=transform)\n",
    "test_loader = DataLoader(test_data,shuffle=True,batch_size=64)\n",
    "print(train_data)\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba21bf-a132-418e-a5e1-55fa16e4f94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
